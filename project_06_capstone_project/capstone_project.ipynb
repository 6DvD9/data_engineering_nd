{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL Pipeline for Immigration and Temperature data\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The goal of this project is to create an ETL pipeline using I94 immigration data and city temperature data to form a database that is optimized for queries on immigration events. This database can then be used to answer questions relating to immigration behavior regarding destination area temperature, such as: Do people prefer to immigrate to warmer places?\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "In this project, we will aggregate I94 immigration data by destination city to form our first dimension table. Next we will aggregate city temperature data by city to form the second dimension table. The two datasets will be joined on destination city to form the fact table. The final database is optimized to query on immigration events to determine if temperature affects the selection of destination cities. Spark will be used to process the data.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "The I94 immigration [data](https://travel.trade.gov/research/reports/i94/historical/2016.html) comes from the US National Tourism and Trade Office. It is provided in SAS7BDAT [format](https://cran.r-project.org/web/packages/sas7bdat/vignettes/sas7bdat.pdf) which is a binary database storage format. Some relevant attributes include:\n",
    "\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = numeric month\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination USA city\n",
    "* arrdate = arrival date in the USA\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date from the USA\n",
    "* i94visa = reason for immigration\n",
    "\n",
    "The temperature [data](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) comes from Kaggle. It is provided in csv format. Some relevant attributes include:\n",
    "\n",
    "* AverageTemperature = average temperature\n",
    "* City = city name\n",
    "* Country = country name\n",
    "* Latitude= latitude\n",
    "* Longitude = longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20636.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20640.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>09282016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OZ</td>\n",
       "      <td>6.309290e+10</td>\n",
       "      <td>00202</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20636.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20657.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>09282016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DL</td>\n",
       "      <td>6.309290e+10</td>\n",
       "      <td>09858</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>20636.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20657.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>09282016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VS</td>\n",
       "      <td>6.309290e+10</td>\n",
       "      <td>00071</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>TAM</td>\n",
       "      <td>20636.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20645.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>09282016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>6.309290e+10</td>\n",
       "      <td>00482</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20636.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20662.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>09282016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SU</td>\n",
       "      <td>6.309290e+10</td>\n",
       "      <td>00106</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    1.0  2016.0     7.0   254.0   276.0     LOS  20636.0      1.0      CA   \n",
       "1    2.0  2016.0     7.0   140.0   140.0     NYC  20636.0      1.0      NY   \n",
       "2    3.0  2016.0     7.0   135.0   135.0     ORL  20636.0      1.0      FL   \n",
       "3    4.0  2016.0     7.0   124.0   124.0     TAM  20636.0      1.0      FL   \n",
       "4    5.0  2016.0     7.0   130.0   130.0     LOS  20636.0      1.0      CA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0  20640.0   ...         NaN        M   1978.0  09282016      M    NaN   \n",
       "1  20657.0   ...         NaN        M   1971.0  09282016      F    NaN   \n",
       "2  20657.0   ...         NaN        M   2006.0  09282016      M    NaN   \n",
       "3  20645.0   ...         NaN        M   1999.0  09282016      M    NaN   \n",
       "4  20662.0   ...         NaN        M   2015.0  09282016      M    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0      OZ  6.309290e+10  00202       WT  \n",
       "1      DL  6.309290e+10  09858       WT  \n",
       "2      VS  6.309290e+10  00071       WT  \n",
       "3      LH  6.309290e+10  00482       WT  \n",
       "4      SU  6.309290e+10  00106       WT  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read July 2016 I94 immigration data into Pandas for exploration\n",
    "file_loc = '../../data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat'\n",
    "july_df = pd.read_sas(file_loc, 'sas7bdat', encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "july_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4265026</th>\n",
       "      <td>686686.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>THO</td>\n",
       "      <td>20638.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20644.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>01022017</td>\n",
       "      <td>F</td>\n",
       "      <td>233734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.636851e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265027</th>\n",
       "      <td>689855.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>THO</td>\n",
       "      <td>20638.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20644.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>01022017</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.636906e+09</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265028</th>\n",
       "      <td>1033772.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>NIA</td>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MD</td>\n",
       "      <td>20690.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>12072016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.165249e+09</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265029</th>\n",
       "      <td>1033774.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>NIA</td>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MD</td>\n",
       "      <td>20690.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>12072016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.166088e+09</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265030</th>\n",
       "      <td>2718366.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>NIA</td>\n",
       "      <td>20647.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20655.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>12142016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.915644e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "4265026   686686.0  2016.0     7.0   745.0   745.0     THO  20638.0      3.0   \n",
       "4265027   689855.0  2016.0     7.0   745.0   745.0     THO  20638.0      3.0   \n",
       "4265028  1033772.0  2016.0     7.0   111.0   749.0     NIA  20640.0      3.0   \n",
       "4265029  1033774.0  2016.0     7.0   111.0   749.0     NIA  20640.0      3.0   \n",
       "4265030  2718366.0  2016.0     7.0   574.0   749.0     NIA  20647.0      3.0   \n",
       "\n",
       "        i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "4265026      NJ  20644.0   ...         NaN        M   1951.0  01022017      F   \n",
       "4265027      NJ  20644.0   ...         NaN        M   1946.0  01022017      M   \n",
       "4265028      MD  20690.0   ...         NaN        M   1990.0  12072016      F   \n",
       "4265029      MD  20690.0   ...         NaN        M   2007.0  12072016      F   \n",
       "4265030      NY  20655.0   ...         NaN        M   1956.0  12142016      M   \n",
       "\n",
       "         insnum airline        admnum fltno visatype  \n",
       "4265026  233734     NaN  1.636851e+09   NaN       B2  \n",
       "4265027     NaN     NaN  1.636906e+09  LAND       B2  \n",
       "4265028     NaN     NaN  1.165249e+09  LAND       B2  \n",
       "4265029     NaN     NaN  1.166088e+09  LAND       B2  \n",
       "4265030     NaN     NaN  9.915644e+10  LAND       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the last 5 rows of the dataframe\n",
    "july_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4265031, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dislay the shape of the dataframe\n",
    "july_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Ã…rhus   \n",
       "1  1743-12-01                 NaN                            NaN  Ã…rhus   \n",
       "2  1744-01-01                 NaN                            NaN  Ã…rhus   \n",
       "3  1744-02-01                 NaN                            NaN  Ã…rhus   \n",
       "4  1744-03-01                 NaN                            NaN  Ã…rhus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the temperature data into Pandas for exploration\n",
    "file_loc = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temp_df = pd.read_csv(file_loc, sep=',')\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8599207</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>11.464</td>\n",
       "      <td>0.236</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599208</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>15.043</td>\n",
       "      <td>0.261</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599209</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>18.775</td>\n",
       "      <td>0.193</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599210</th>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>18.025</td>\n",
       "      <td>0.298</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599211</th>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
       "8599207  2013-05-01              11.464                          0.236   \n",
       "8599208  2013-06-01              15.043                          0.261   \n",
       "8599209  2013-07-01              18.775                          0.193   \n",
       "8599210  2013-08-01              18.025                          0.298   \n",
       "8599211  2013-09-01                 NaN                            NaN   \n",
       "\n",
       "           City      Country Latitude Longitude  \n",
       "8599207  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599208  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599209  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599210  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599211  Zwolle  Netherlands   52.24N     5.26E  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the last 5 rows of the dataframe\n",
    "temp_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8599212, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a spark session with sas7bdat\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\") \\\n",
    "    .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Clean the data\n",
    "\n",
    "For the I94 immigration data, we want to drop all entries where the destination city code i94port is not a valid value (e.g., XXX, 99, etc) as described in I94_SAS_Labels_Description.SAS. \n",
    "\n",
    "For the temperature data, we want to drop all entries where AverageTemperature is NaN, then drop all entries with duplicate locations, and then add the i94port of the location in each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean I94 immigration data\n",
    "\n",
    "# Create dictionary of valid i94port codes\n",
    "re_obj = re.compile(r'\\'(.*)\\'.*\\'(.*)\\'')\n",
    "i94port_valid = {}\n",
    "with open('i94port_valid.txt') as f:\n",
    "     for line in f:\n",
    "         match = re_obj.search(line)\n",
    "         i94port_valid[match[1]]=[match[2]]\n",
    "\n",
    "def clean_i94_data(file):\n",
    "    \"\"\"\n",
    "    Input: Path to I94 immigration data file\n",
    "    Output: Spark dataframe of I94 immigration data with valid i94port\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read I94 data into Spark\n",
    "    df_immigration = spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "\n",
    "    # Filter out entries where i94port is invalid\n",
    "    df_immigration = df_immigration.filter(df_immigration.i94port.isin(list(i94port_valid.keys())))\n",
    "\n",
    "    return df_immigration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|         admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|  1.0|2016.0|   7.0| 254.0| 276.0|    LOS|20636.0|    1.0|     CA|20640.0|  38.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1978.0|09282016|     M|  null|     OZ|6.3092898033E10|00202|      WT|\n",
      "|  2.0|2016.0|   7.0| 140.0| 140.0|    NYC|20636.0|    1.0|     NY|20657.0|  45.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1971.0|09282016|     F|  null|     DL|6.3092899033E10|09858|      WT|\n",
      "|  3.0|2016.0|   7.0| 135.0| 135.0|    ORL|20636.0|    1.0|     FL|20657.0|  10.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 2006.0|09282016|     M|  null|     VS|6.3092900933E10|00071|      WT|\n",
      "|  4.0|2016.0|   7.0| 124.0| 124.0|    TAM|20636.0|    1.0|     FL|20645.0|  17.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1999.0|09282016|     M|  null|     LH|6.3092901833E10|00482|      WT|\n",
      "|  5.0|2016.0|   7.0| 130.0| 130.0|    LOS|20636.0|    1.0|     CA|20662.0|   1.0|    2.0|  1.0|20160701|    null| null|      G|      K|   null|      M| 2015.0|09282016|     M|  null|     SU|6.3092902733E10|00106|      WT|\n",
      "|  6.0|2016.0|   7.0| 135.0| 135.0|    SFR|20636.0|    1.0|     CA|20648.0|  51.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1965.0|09282016|     M|  null|     BA|6.3092903633E10|00285|      WT|\n",
      "|  7.0|2016.0|   7.0| 115.0| 115.0|    OAK|20636.0|    1.0|     CA|20646.0|  13.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 2003.0|09282016|     F|  null|     DY|6.3092904533E10|07067|      WT|\n",
      "|  8.0|2016.0|   7.0| 438.0| 438.0|    HHW|20636.0|    1.0|     HI|20644.0|  34.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1982.0|09282016|     F|  null|     QF|6.3092905433E10|00003|      WT|\n",
      "|  9.0|2016.0|   7.0| 131.0| 131.0|    LVG|20636.0|    1.0|     NV|20657.0|  46.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1970.0|09282016|     M|  null|     WK|6.3092906333E10|00002|      WT|\n",
      "| 10.0|2016.0|   7.0| 140.0| 140.0|    LOS|20636.0|    1.0|     CA|20656.0|  44.0|    2.0|  1.0|20160701|    null| null|      O|      O|   null|      M| 1972.0|09282016|  null|  null|     SU|6.3092907233E10|00106|      WT|\n",
      "| 12.0|2016.0|   7.0| 131.0| 131.0|    LVG|20636.0|    1.0|     NV|20663.0|  25.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1991.0|09282016|     M|  null|     WK|6.3092909033E10|00002|      WT|\n",
      "| 13.0|2016.0|   7.0| 140.0| 140.0|    LOS|20636.0|    1.0|     CA|20656.0|  12.0|    2.0|  1.0|20160701|    null| null|      O|      O|   null|      M| 2004.0|09282016|  null|  null|     SU|6.3092910033E10|00106|      WT|\n",
      "| 14.0|2016.0|   7.0| 135.0| 135.0|    SFR|20636.0|    1.0|     CA|20642.0|  30.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1986.0|09282016|     M|  null|     BA|6.3092911933E10|00285|      WT|\n",
      "| 15.0|2016.0|   7.0| 140.0| 140.0|    LOS|20636.0|    1.0|     CA|20656.0|  45.0|    2.0|  1.0|20160701|    null| null|      O|      O|   null|      M| 1971.0|09282016|  null|  null|     SU|6.3092912833E10|00106|      WT|\n",
      "| 16.0|2016.0|   7.0| 135.0| 135.0|    ORL|20636.0|    1.0|     FL|20650.0|  13.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 2003.0|09282016|     F|  null|     VS|6.3092913733E10|00071|      WT|\n",
      "| 17.0|2016.0|   7.0| 108.0| 108.0|    SEA|20636.0|    1.0|     AK|20642.0|  42.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1974.0|09282016|     M|  null|     DL|6.3092914633E10|00145|      WT|\n",
      "| 18.0|2016.0|   7.0| 131.0| 131.0|    LVG|20636.0|    1.0|     NV|20657.0|  71.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1945.0|09282016|     M|  null|     WK|6.3092915533E10|00002|      WT|\n",
      "| 20.0|2016.0|   7.0| 135.0| 135.0|    ORL|20636.0|    1.0|     FL|20652.0|  14.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 2002.0|09282016|     M|  null|     VS|6.3092917333E10|00071|      WT|\n",
      "| 21.0|2016.0|   7.0| 209.0| 209.0|    BOS|20636.0|    1.0|     MA|20640.0|  60.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1956.0|09282016|     F|  null|     JL|6.3092918233E10|00008|      WT|\n",
      "| 22.0|2016.0|   7.0| 104.0| 104.0|    LVG|20636.0|    1.0|     NV|20651.0|  25.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1991.0|09282016|     M|  null|     WK|6.3092919133E10|00002|      WT|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test function\n",
    "file_loc = '../../data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat'\n",
    "df_immigration_test = clean_i94_data(file_loc)\n",
    "df_immigration_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean temperature data\n",
    "df_temp=spark.read.format(\"csv\").option(\"header\", \"true\").load(\"../../data2/GlobalLandTemperaturesByCity.csv\")\n",
    "\n",
    "# Filter out entries with NaN average temperature\n",
    "df_temp=df_temp.filter(df_temp.AverageTemperature != 'NaN')\n",
    "\n",
    "# Remove duplicate locations\n",
    "df_temp=df_temp.dropDuplicates(['City', 'Country'])\n",
    "\n",
    "@udf()\n",
    "def get_i94port(city):\n",
    "    \"\"\"\n",
    "    Input: City name\n",
    "    Output: Corresponding i94port\n",
    "    \"\"\"\n",
    "    for key in i94port_valid:\n",
    "        if city.lower() in i94port_valid[key][0].lower():\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add iport94 code based on city name\n",
    "df_temp=df_temp.withColumn(\"i94port\", get_i94port(df_temp.City))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove entries with no iport94 code\n",
    "df_temp=df_temp.filter(df_temp.i94port != 'null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-----------------------------+---------+--------------------+--------+---------+-------+\n",
      "|        dt| AverageTemperature|AverageTemperatureUncertainty|     City|             Country|Latitude|Longitude|i94port|\n",
      "+----------+-------------------+-----------------------------+---------+--------------------+--------+---------+-------+\n",
      "|1852-07-01|             15.488|                        1.395|    Perth|           Australia|  31.35S|  114.97E|    PER|\n",
      "|1828-01-01|             -1.977|                        2.551|  Seattle|       United States|  47.42N|  121.97W|    SEA|\n",
      "|1743-11-01|              2.767|                        1.905| Hamilton|              Canada|  42.59N|   80.73W|    HAM|\n",
      "|1849-01-01|  7.399999999999999|                        2.699|  Ontario|       United States|  34.56N|  116.76W|    ONT|\n",
      "|1821-11-01|              2.322|                        2.375|  Spokane|       United States|  47.42N|  117.24W|    SPO|\n",
      "|1843-01-01| 18.874000000000002|                        2.017|Abu Dhabi|United Arab Emirates|  24.92N|   54.98E|    MAA|\n",
      "|1824-01-01|             25.229|                        1.094|    Anaco|           Venezuela|   8.84N|   64.05W|    ANA|\n",
      "|1855-05-01|              9.904|           1.4369999999999998|      Ica|                Peru|  13.66S|   75.14W|    CHI|\n",
      "|1835-01-01|              9.833|                        2.182|  Nogales|       United States|  31.35N|  111.20W|    NOG|\n",
      "|1743-11-01|  8.129999999999999|                        2.245|  Atlanta|       United States|  34.56N|   83.68W|    ATL|\n",
      "|1796-01-01|             15.552|                        2.305|      Mau|               India|  26.52N|   84.18E|    OGG|\n",
      "|1743-11-01|              3.264|                        1.665|   Newark|       United States|  40.99N|   74.56W|    NEW|\n",
      "|1857-01-01| 18.581000000000003|           1.8119999999999998|  Springs|        South Africa|  26.52S|   28.66E|    PSP|\n",
      "|1856-01-01| 26.055999999999997|           1.3769999999999998|      Ise|             Nigeria|   7.23N|    5.68E|    BOI|\n",
      "|1743-11-01|             18.722|                        2.302|  Orlando|       United States|  28.13N|   80.91W|    ORL|\n",
      "|1823-01-01|             11.602|           2.8160000000000003|   Laredo|       United States|  28.13N|   99.09W|    LCB|\n",
      "|1841-01-01| 13.107999999999999|                        2.519|     Tali|              Taiwan|  24.92N|  120.59E|    MET|\n",
      "|1828-01-01|-2.7630000000000003|                        2.617| Victoria|              Canada|  49.03N|  122.45W|    VIC|\n",
      "|1743-11-01| 1.1880000000000002|                        1.531|   Boston|       United States|  42.59N|   72.00W|    BOS|\n",
      "|1849-01-01|  8.091999999999999|           2.1919999999999997|Fairfield|       United States|  37.78N|  122.03W|    FTF|\n",
      "+----------+-------------------+-----------------------------+---------+--------------------+--------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "df_temp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The first dimension table will contain events from the I94 immigration data. \n",
    "The columns below will be extracted from the immigration dataframe:\n",
    "\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = numeric month\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination city\n",
    "* arrdate = arrival date\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date\n",
    "* i94visa = reason for immigration\n",
    "\n",
    "The second dimension table will contain city temperature data. \n",
    "The columns below will be extracted from the temperature dataframe:\n",
    "\n",
    "* i94port = 3 character code of destination city (mapped from immigration data during cleanup step)\n",
    "* AverageTemperature = average temperature\n",
    "* City = city name\n",
    "* Country = country name\n",
    "* Latitude= latitude\n",
    "* Longitude = longitude\n",
    "\n",
    "The fact table will contain information from the I94 immigration data joined with the city temperature data on i94port:\n",
    "\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = numeric month\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination city\n",
    "* arrdate = arrival date\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date\n",
    "* i94visa = reason for immigration\n",
    "* AverageTemperature = average temperature of destination city\n",
    "\n",
    "The tables will be saved to Parquet files partitioned by city (i94port).\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "The pipeline steps are described below:\n",
    "\n",
    "1. Clean I94 data as described in step 2 to create Spark dataframe df_immigration for each month\n",
    "2. Clean temperature data as described in step 2 to create Spark dataframe df_temp (already performed)\n",
    "3. Create immigration dimension table by selecting relevant columns from df_immigration and write to parquet file partitioned by i94port\n",
    "4. Create temperature dimension table by selecting relevant columns from df_temp and write to parquet file partitioned by i94port\n",
    "5. Create fact table by joining immigration and temperature dimension tables on i94port and write to parquet file partitioned by i94port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|         admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|  1.0|2016.0|   7.0| 254.0| 276.0|    LOS|20636.0|    1.0|     CA|20640.0|  38.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1978.0|09282016|     M|  null|     OZ|6.3092898033E10|00202|      WT|\n",
      "|  2.0|2016.0|   7.0| 140.0| 140.0|    NYC|20636.0|    1.0|     NY|20657.0|  45.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1971.0|09282016|     F|  null|     DL|6.3092899033E10|09858|      WT|\n",
      "|  3.0|2016.0|   7.0| 135.0| 135.0|    ORL|20636.0|    1.0|     FL|20657.0|  10.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 2006.0|09282016|     M|  null|     VS|6.3092900933E10|00071|      WT|\n",
      "|  4.0|2016.0|   7.0| 124.0| 124.0|    TAM|20636.0|    1.0|     FL|20645.0|  17.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1999.0|09282016|     M|  null|     LH|6.3092901833E10|00482|      WT|\n",
      "|  5.0|2016.0|   7.0| 130.0| 130.0|    LOS|20636.0|    1.0|     CA|20662.0|   1.0|    2.0|  1.0|20160701|    null| null|      G|      K|   null|      M| 2015.0|09282016|     M|  null|     SU|6.3092902733E10|00106|      WT|\n",
      "|  6.0|2016.0|   7.0| 135.0| 135.0|    SFR|20636.0|    1.0|     CA|20648.0|  51.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1965.0|09282016|     M|  null|     BA|6.3092903633E10|00285|      WT|\n",
      "|  7.0|2016.0|   7.0| 115.0| 115.0|    OAK|20636.0|    1.0|     CA|20646.0|  13.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 2003.0|09282016|     F|  null|     DY|6.3092904533E10|07067|      WT|\n",
      "|  8.0|2016.0|   7.0| 438.0| 438.0|    HHW|20636.0|    1.0|     HI|20644.0|  34.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1982.0|09282016|     F|  null|     QF|6.3092905433E10|00003|      WT|\n",
      "|  9.0|2016.0|   7.0| 131.0| 131.0|    LVG|20636.0|    1.0|     NV|20657.0|  46.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1970.0|09282016|     M|  null|     WK|6.3092906333E10|00002|      WT|\n",
      "| 10.0|2016.0|   7.0| 140.0| 140.0|    LOS|20636.0|    1.0|     CA|20656.0|  44.0|    2.0|  1.0|20160701|    null| null|      O|      O|   null|      M| 1972.0|09282016|  null|  null|     SU|6.3092907233E10|00106|      WT|\n",
      "| 12.0|2016.0|   7.0| 131.0| 131.0|    LVG|20636.0|    1.0|     NV|20663.0|  25.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1991.0|09282016|     M|  null|     WK|6.3092909033E10|00002|      WT|\n",
      "| 13.0|2016.0|   7.0| 140.0| 140.0|    LOS|20636.0|    1.0|     CA|20656.0|  12.0|    2.0|  1.0|20160701|    null| null|      O|      O|   null|      M| 2004.0|09282016|  null|  null|     SU|6.3092910033E10|00106|      WT|\n",
      "| 14.0|2016.0|   7.0| 135.0| 135.0|    SFR|20636.0|    1.0|     CA|20642.0|  30.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1986.0|09282016|     M|  null|     BA|6.3092911933E10|00285|      WT|\n",
      "| 15.0|2016.0|   7.0| 140.0| 140.0|    LOS|20636.0|    1.0|     CA|20656.0|  45.0|    2.0|  1.0|20160701|    null| null|      O|      O|   null|      M| 1971.0|09282016|  null|  null|     SU|6.3092912833E10|00106|      WT|\n",
      "| 16.0|2016.0|   7.0| 135.0| 135.0|    ORL|20636.0|    1.0|     FL|20650.0|  13.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 2003.0|09282016|     F|  null|     VS|6.3092913733E10|00071|      WT|\n",
      "| 17.0|2016.0|   7.0| 108.0| 108.0|    SEA|20636.0|    1.0|     AK|20642.0|  42.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1974.0|09282016|     M|  null|     DL|6.3092914633E10|00145|      WT|\n",
      "| 18.0|2016.0|   7.0| 131.0| 131.0|    LVG|20636.0|    1.0|     NV|20657.0|  71.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1945.0|09282016|     M|  null|     WK|6.3092915533E10|00002|      WT|\n",
      "| 20.0|2016.0|   7.0| 135.0| 135.0|    ORL|20636.0|    1.0|     FL|20652.0|  14.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 2002.0|09282016|     M|  null|     VS|6.3092917333E10|00071|      WT|\n",
      "| 21.0|2016.0|   7.0| 209.0| 209.0|    BOS|20636.0|    1.0|     MA|20640.0|  60.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1956.0|09282016|     F|  null|     JL|6.3092918233E10|00008|      WT|\n",
      "| 22.0|2016.0|   7.0| 104.0| 104.0|    LVG|20636.0|    1.0|     NV|20651.0|  25.0|    2.0|  1.0|20160701|    null| null|      G|      O|   null|      M| 1991.0|09282016|     M|  null|     WK|6.3092919133E10|00002|      WT|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Location to I94 immigration data \n",
    "file_loc = '../../data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat'\n",
    "\n",
    "# Clean I94 immigration data and store as Spark dataframe\n",
    "df_immigration = clean_i94_data(file_loc)\n",
    "\n",
    "# Show results\n",
    "df_immigration.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4247749"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the row count\n",
    "df_immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+-------+-------+-------+-------+\n",
      "| i94yr|i94mon|i94cit|i94port|arrdate|i94mode|depdate|i94visa|\n",
      "+------+------+------+-------+-------+-------+-------+-------+\n",
      "|2016.0|   7.0| 254.0|    LOS|20636.0|    1.0|20640.0|    2.0|\n",
      "|2016.0|   7.0| 140.0|    NYC|20636.0|    1.0|20657.0|    2.0|\n",
      "|2016.0|   7.0| 135.0|    ORL|20636.0|    1.0|20657.0|    2.0|\n",
      "|2016.0|   7.0| 124.0|    TAM|20636.0|    1.0|20645.0|    2.0|\n",
      "|2016.0|   7.0| 130.0|    LOS|20636.0|    1.0|20662.0|    2.0|\n",
      "|2016.0|   7.0| 135.0|    SFR|20636.0|    1.0|20648.0|    2.0|\n",
      "|2016.0|   7.0| 115.0|    OAK|20636.0|    1.0|20646.0|    2.0|\n",
      "|2016.0|   7.0| 438.0|    HHW|20636.0|    1.0|20644.0|    2.0|\n",
      "|2016.0|   7.0| 131.0|    LVG|20636.0|    1.0|20657.0|    2.0|\n",
      "|2016.0|   7.0| 140.0|    LOS|20636.0|    1.0|20656.0|    2.0|\n",
      "|2016.0|   7.0| 131.0|    LVG|20636.0|    1.0|20663.0|    2.0|\n",
      "|2016.0|   7.0| 140.0|    LOS|20636.0|    1.0|20656.0|    2.0|\n",
      "|2016.0|   7.0| 135.0|    SFR|20636.0|    1.0|20642.0|    2.0|\n",
      "|2016.0|   7.0| 140.0|    LOS|20636.0|    1.0|20656.0|    2.0|\n",
      "|2016.0|   7.0| 135.0|    ORL|20636.0|    1.0|20650.0|    2.0|\n",
      "|2016.0|   7.0| 108.0|    SEA|20636.0|    1.0|20642.0|    2.0|\n",
      "|2016.0|   7.0| 131.0|    LVG|20636.0|    1.0|20657.0|    2.0|\n",
      "|2016.0|   7.0| 135.0|    ORL|20636.0|    1.0|20652.0|    2.0|\n",
      "|2016.0|   7.0| 209.0|    BOS|20636.0|    1.0|20640.0|    2.0|\n",
      "|2016.0|   7.0| 104.0|    LVG|20636.0|    1.0|20651.0|    2.0|\n",
      "+------+------+------+-------+-------+-------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create immigration dimension table by extracting columns from df_immigration\n",
    "immigration_table = df_immigration.select([\"i94yr\", \"i94mon\", \"i94cit\", \"i94port\", \"arrdate\", \"i94mode\", \"depdate\", \"i94visa\"])\n",
    "\n",
    "# Show results\n",
    "immigration_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4247749"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the row count\n",
    "immigration_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write immigration dimension table to parquet files partitioned by i94port\n",
    "immigration_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/home/workspace/results/immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------------------+--------+---------+-------+\n",
      "| AverageTemperature|     City|             Country|Latitude|Longitude|i94port|\n",
      "+-------------------+---------+--------------------+--------+---------+-------+\n",
      "|             15.488|    Perth|           Australia|  31.35S|  114.97E|    PER|\n",
      "|             -1.977|  Seattle|       United States|  47.42N|  121.97W|    SEA|\n",
      "|              2.767| Hamilton|              Canada|  42.59N|   80.73W|    HAM|\n",
      "|  7.399999999999999|  Ontario|       United States|  34.56N|  116.76W|    ONT|\n",
      "|              2.322|  Spokane|       United States|  47.42N|  117.24W|    SPO|\n",
      "| 18.874000000000002|Abu Dhabi|United Arab Emirates|  24.92N|   54.98E|    MAA|\n",
      "|             25.229|    Anaco|           Venezuela|   8.84N|   64.05W|    ANA|\n",
      "|              9.904|      Ica|                Peru|  13.66S|   75.14W|    CHI|\n",
      "|              9.833|  Nogales|       United States|  31.35N|  111.20W|    NOG|\n",
      "|  8.129999999999999|  Atlanta|       United States|  34.56N|   83.68W|    ATL|\n",
      "|             15.552|      Mau|               India|  26.52N|   84.18E|    OGG|\n",
      "|              3.264|   Newark|       United States|  40.99N|   74.56W|    NEW|\n",
      "| 18.581000000000003|  Springs|        South Africa|  26.52S|   28.66E|    PSP|\n",
      "| 26.055999999999997|      Ise|             Nigeria|   7.23N|    5.68E|    BOI|\n",
      "|             18.722|  Orlando|       United States|  28.13N|   80.91W|    ORL|\n",
      "|             11.602|   Laredo|       United States|  28.13N|   99.09W|    LCB|\n",
      "| 13.107999999999999|     Tali|              Taiwan|  24.92N|  120.59E|    MET|\n",
      "|-2.7630000000000003| Victoria|              Canada|  49.03N|  122.45W|    VIC|\n",
      "| 1.1880000000000002|   Boston|       United States|  42.59N|   72.00W|    BOS|\n",
      "|  8.091999999999999|Fairfield|       United States|  37.78N|  122.03W|    FTF|\n",
      "+-------------------+---------+--------------------+--------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create temperature dimension table by extracting columns from df_temp\n",
    "temp_table = df_temp.select([\"AverageTemperature\", \"City\", \"Country\", \"Latitude\", \"Longitude\", \"i94port\"])\n",
    "\n",
    "# Show results\n",
    "temp_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the row count\n",
    "temp_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write temperature dimension table to parquet files partitioned by i94port\n",
    "temp_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/home/workspace/results/temperature.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create temporary views of the immigration and temperature data\n",
    "df_immigration.createOrReplaceTempView(\"immigration_view\")\n",
    "df_temp.createOrReplaceTempView(\"temp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+-------+------------+--------------+------+-----------------+--------+---------+\n",
      "|  year|month| city|i94port|arrival_date|departure_date|reason|      temperature|latitude|longitude|\n",
      "+------+-----+-----+-------+------------+--------------+------+-----------------+--------+---------+\n",
      "|2016.0|  7.0|690.0|    SNA|     20636.0|       20645.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|690.0|    SNA|     20636.0|       20645.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|690.0|    SNA|     20636.0|       20645.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|690.0|    SNA|     20636.0|       20645.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|129.0|    SNA|     20636.0|       20650.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|690.0|    SNA|     20636.0|       20645.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|690.0|    SNA|     20636.0|       20645.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|690.0|    SNA|     20636.0|       20645.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|690.0|    SNA|     20636.0|       20664.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|129.0|    SNA|     20636.0|       20648.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|148.0|    SNA|     20636.0|       20645.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|690.0|    SNA|     20636.0|       20652.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|690.0|    SNA|     20636.0|       20664.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|690.0|    SNA|     20636.0|       20664.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|690.0|    SNA|     20636.0|       20664.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|103.0|    SNA|     20636.0|       20638.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|129.0|    SNA|     20636.0|       20642.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|117.0|    SNA|     20636.0|       20641.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|126.0|    SNA|     20636.0|       20638.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "|2016.0|  7.0|582.0|    SNA|     20636.0|       20638.0|   2.0|7.168999999999999|  29.74N|   97.85W|\n",
      "+------+-----+-----+-------+------------+--------------+------+-----------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the fact table by joining the immigration and temperature views\n",
    "fact_table = spark.sql('''\n",
    "SELECT immigration_view.i94yr as year,\n",
    "       immigration_view.i94mon as month,\n",
    "       immigration_view.i94cit as city,\n",
    "       immigration_view.i94port as i94port,\n",
    "       immigration_view.arrdate as arrival_date,\n",
    "       immigration_view.depdate as departure_date,\n",
    "       immigration_view.i94visa as reason,\n",
    "       temp_view.AverageTemperature as temperature,\n",
    "       temp_view.Latitude as latitude,\n",
    "       temp_view.Longitude as longitude\n",
    "FROM immigration_view\n",
    "JOIN temp_view ON (immigration_view.i94port = temp_view.i94port)\n",
    "''')\n",
    "\n",
    "# Show results\n",
    "fact_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the row count\n",
    "fact_table.count()\n",
    "\n",
    "### Taking too long to run this cell... Stopped it\n",
    "### https://stackoverflow.com/questions/45142105/count-on-spark-dataframe-is-extremely-slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write fact table to parquet files partitioned by i94port\n",
    "fact_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/home/workspace/results/fact.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "The data quality check will that there are correct number of entries in each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def quality_check(df, description):\n",
    "    \"\"\"\n",
    "    Input: spark_dataframe table, description of spark dataframe table\n",
    "    Output: print outcome of data quality check\n",
    "    \"\"\"\n",
    "    result = df.count()\n",
    "    if result == 0:\n",
    "        print(f\"Data quality check failed for {description} with zero records\")\n",
    "    else:\n",
    "        print(f\"Data quality check passed for {description} with {result} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for immigration table with 4247749 records\n"
     ]
    }
   ],
   "source": [
    "# Quality check on immigration table\n",
    "quality_check(immigration_table, \"immigration table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Quality check on temperature table\n",
    "quality_check(temp_table, \"temperature table\")\n",
    "\n",
    "### Taking too long, please refer to cell 21\n",
    "### https://stackoverflow.com/questions/45142105/count-on-spark-dataframe-is-extremely-slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Quality check on fact table\n",
    "quality_check(temp_table, \"temperature table\")\n",
    "\n",
    "### Taking too long to run this cell... Stopped it\n",
    "### https://stackoverflow.com/questions/45142105/count-on-spark-dataframe-is-extremely-slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "The first dimension table will contain events from the I94 immigration data. The columns below will be extracted from the immigration dataframe:\n",
    "\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = numeric month\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination city\n",
    "* arrdate = arrival date\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date\n",
    "* i94visa = reason for immigration\n",
    "\n",
    "The second dimension table will contain city temperature data. The columns below will be extracted from the temperature dataframe:\n",
    "\n",
    "* i94port = 3 character code of destination city (mapped from immigration data during cleanup step)\n",
    "* AverageTemperature = average temperature\n",
    "* City = city name\n",
    "* Country = country name\n",
    "* Latitude = latitude\n",
    "* Longitude = longitude\n",
    "\n",
    "The fact table will contain information from the I94 immigration data joined with the city temperature data on i94port:\n",
    "\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = numeric month\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination city\n",
    "* arrdate = arrival date\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date\n",
    "* i94visa = reason for immigration\n",
    "* AverageTemperature = average temperature of destination city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "1. Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "    * For this project I used pandas for initial investigation of data, and then apache spark to read, transform and create data outputs for further analysis as it can easily handle multiple file formats (including SAS) containing large amounts of data.  \n",
    "\n",
    "\n",
    "2. Propose how often the data should be updated and why.\n",
    "\n",
    "    * Since data was taken from monthly files, data should be run monthly. This should give the most up to date data for government and organisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Write a description of how you would approach the problem differently under the following scenarios:\n",
    "\n",
    "3. The data was increased by 100x.\n",
    "\n",
    "    * If the data was increased by 100x, I would go with Apache Hadoop to create a distributed processing system for faster processing.\n",
    "\n",
    "\n",
    "4. The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "\n",
    "    * To update on a daily basis I would go with Apache Airflow to create a schedule to run a distributed update on all tables with data streamed from the source.\n",
    "\n",
    "\n",
    "5. The database needed to be accessed by 100+ people.\n",
    "\n",
    "    * If the data needs to be accessed by 100+ people, I would probably build a serverless web app running on Amazon AWS where scaling is set to auto so that it can scale up when required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
